{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ssd.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"ALdQb3sBOH_v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d8cb3c3e-97c2-4d08-fb72-bd3f47f828f3","executionInfo":{"status":"ok","timestamp":1539522320827,"user_tz":-540,"elapsed":6528,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import shutil\n","import zipfile"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"qjuTItzaOKcB","colab_type":"code","colab":{}},"cell_type":"code","source":["shutil.copyfile(\"./gdrive/My Drive/data/2007/2007.zip\", \"./2007.zip\")\n","with zipfile.ZipFile('./2007.zip') as existing_zip:\n","  existing_zip.extractall('./')\n","shutil.copyfile(\"./gdrive/My Drive/data/2007/param.hdf5\", \"./params.hdf5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"351oX2gQN0YF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ed08634a-fb7e-4b76-d4c7-bc907f17d961","executionInfo":{"status":"ok","timestamp":1539505787386,"user_tz":-540,"elapsed":4353,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["import cv2\n","import keras\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.backend.tensorflow_backend import set_session\n","from keras.models import Model\n","from keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","from random import shuffle\n","from scipy.misc import imread\n","from scipy.misc import imresize\n","import tensorflow as tf\n","\n","from ssd import SSD300\n","from ssd_training import MultiboxLoss\n","from ssd_utils import BBoxUtility"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"TXcoxOclOFHM","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.rcParams['figure.figsize'] = (8, 8)\n","plt.rcParams['image.interpolation'] = 'nearest'\n","\n","np.set_printoptions(suppress=True)\n","\n","# 21\n","NUM_CLASSES = 21 #4\n","input_shape = (300, 300, 3)\n","\n","priors = pickle.load(open('prior_boxes_ssd300.pkl', 'rb'))\n","bbox_util = BBoxUtility(NUM_CLASSES, priors)\n","\n","# gt = pickle.load(open('gt_pascal.pkl', 'rb'))\n","gt = pickle.load(open('VOC2007.pkl', 'rb'))\n","keys = sorted(gt.keys())\n","num_train = int(round(0.8 * len(keys)))\n","train_keys = keys[:num_train]\n","val_keys = keys[num_train:]\n","num_val = len(val_keys)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r26zJ5ZwMd72","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1320},"outputId":"088e482a-3c35-49fc-b8d8-aa985049e815","executionInfo":{"status":"ok","timestamp":1539508038203,"user_tz":-540,"elapsed":3594,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["class Generator(object):\n","    def __init__(self, gt, bbox_util,\n","                 batch_size, path_prefix,\n","                 train_keys, val_keys, image_size,\n","                 saturation_var=0.5,\n","                 brightness_var=0.5,\n","                 contrast_var=0.5,\n","                 lighting_std=0.5,\n","                 hflip_prob=0.5,\n","                 vflip_prob=0.5,\n","                 do_crop=True,\n","                 crop_area_range=[0.75, 1.0],\n","                 aspect_ratio_range=[3./4., 4./3.]):\n","        self.gt = gt\n","        self.bbox_util = bbox_util\n","        self.batch_size = batch_size\n","        self.path_prefix = path_prefix\n","        self.train_keys = train_keys\n","        self.val_keys = val_keys\n","        self.train_batches = len(train_keys)\n","        self.val_batches = len(val_keys)\n","        self.image_size = image_size\n","        self.color_jitter = []\n","        if saturation_var:\n","            self.saturation_var = saturation_var\n","            self.color_jitter.append(self.saturation)\n","        if brightness_var:\n","            self.brightness_var = brightness_var\n","            self.color_jitter.append(self.brightness)\n","        if contrast_var:\n","            self.contrast_var = contrast_var\n","            self.color_jitter.append(self.contrast)\n","        self.lighting_std = lighting_std\n","        self.hflip_prob = hflip_prob\n","        self.vflip_prob = vflip_prob\n","        self.do_crop = do_crop\n","        self.crop_area_range = crop_area_range\n","        self.aspect_ratio_range = aspect_ratio_range\n","\n","    def grayscale(self, rgb):\n","        return rgb.dot([0.299, 0.587, 0.114])\n","\n","    def saturation(self, rgb):\n","        gs = self.grayscale(rgb)\n","        alpha = 2 * np.random.random() * self.saturation_var \n","        alpha += 1 - self.saturation_var\n","        rgb = rgb * alpha + (1 - alpha) * gs[:, :, None]\n","        return np.clip(rgb, 0, 255)\n","\n","    def brightness(self, rgb):\n","        alpha = 2 * np.random.random() * self.brightness_var \n","        alpha += 1 - self.saturation_var\n","        rgb = rgb * alpha\n","        return np.clip(rgb, 0, 255)\n","\n","    def contrast(self, rgb):\n","        gs = self.grayscale(rgb).mean() * np.ones_like(rgb)\n","        alpha = 2 * np.random.random() * self.contrast_var \n","        alpha += 1 - self.contrast_var\n","        rgb = rgb * alpha + (1 - alpha) * gs\n","        return np.clip(rgb, 0, 255)\n","\n","    def lighting(self, img):\n","        cov = np.cov(img.reshape(-1, 3) / 255.0, rowvar=False)\n","        eigval, eigvec = np.linalg.eigh(cov)\n","        noise = np.random.randn(3) * self.lighting_std\n","        noise = eigvec.dot(eigval * noise) * 255\n","        img += noise\n","        return np.clip(img, 0, 255)\n","\n","    def horizontal_flip(self, img, y):\n","        if np.random.random() < self.hflip_prob:\n","            img = img[:, ::-1]\n","            y[:, [0, 2]] = 1 - y[:, [2, 0]]\n","        return img, y\n","\n","    def vertical_flip(self, img, y):\n","        if np.random.random() < self.vflip_prob:\n","            img = img[::-1]\n","            y[:, [1, 3]] = 1 - y[:, [3, 1]]\n","        return img, y\n","\n","    def random_sized_crop(self, img, targets):\n","        img_w = img.shape[1]\n","        img_h = img.shape[0]\n","        img_area = img_w * img_h\n","        random_scale = np.random.random()\n","        random_scale *= (self.crop_area_range[1] -\n","                         self.crop_area_range[0])\n","        random_scale += self.crop_area_range[0]\n","        target_area = random_scale * img_area\n","        random_ratio = np.random.random()\n","        random_ratio *= (self.aspect_ratio_range[1] -\n","                         self.aspect_ratio_range[0])\n","        random_ratio += self.aspect_ratio_range[0]\n","        w = np.round(np.sqrt(target_area * random_ratio))     \n","        h = np.round(np.sqrt(target_area / random_ratio))\n","        if np.random.random() < 0.5:\n","            w, h = h, w\n","        w = min(w, img_w)\n","        w_rel = w / img_w\n","        w = int(w)\n","        h = min(h, img_h)\n","        h_rel = h / img_h\n","        h = int(h)\n","        x = np.random.random() * (img_w - w)\n","        x_rel = x / img_w\n","        x = int(x)\n","        y = np.random.random() * (img_h - h)\n","        y_rel = y / img_h\n","        y = int(y)\n","        img = img[y:y+h, x:x+w]\n","        new_targets = []\n","        for box in targets:\n","            cx = 0.5 * (box[0] + box[2])\n","            cy = 0.5 * (box[1] + box[3])\n","            if (x_rel < cx < x_rel + w_rel and\n","                y_rel < cy < y_rel + h_rel):\n","                xmin = (box[0] - x_rel) / w_rel\n","                ymin = (box[1] - y_rel) / h_rel\n","                xmax = (box[2] - x_rel) / w_rel\n","                ymax = (box[3] - y_rel) / h_rel\n","                xmin = max(0, xmin)\n","                ymin = max(0, ymin)\n","                xmax = min(1, xmax)\n","                ymax = min(1, ymax)\n","                box[:4] = [xmin, ymin, xmax, ymax]\n","                new_targets.append(box)\n","        new_targets = np.asarray(new_targets).reshape(-1, targets.shape[1])\n","        return img, new_targets\n","\n","    def generate(self, train=True):\n","        while True:\n","            if train:\n","                shuffle(self.train_keys)\n","                keys = self.train_keys\n","            else:\n","                shuffle(self.val_keys)\n","                keys = self.val_keys\n","            inputs = []\n","            targets = []\n","            for key in keys:            \n","                img_path = self.path_prefix + key\n","                img = imread(img_path).astype('float32')\n","                y = self.gt[key].copy()\n","                if train and self.do_crop:\n","                    img, y = self.random_sized_crop(img, y)\n","                img = imresize(img, self.image_size).astype('float32')\n","                # boxの位置は正規化されているから画像をリサイズしても\n","                # 教師信号としては問題ない\n","                if train:\n","                    shuffle(self.color_jitter)\n","                    for jitter in self.color_jitter:\n","                        img = jitter(img)\n","                    if self.lighting_std:\n","                        img = self.lighting(img)\n","                    if self.hflip_prob > 0:\n","                        img, y = self.horizontal_flip(img, y)\n","                    if self.vflip_prob > 0:\n","                        img, y = self.vertical_flip(img, y)\n","                # 訓練データ生成時にbbox_utilを使っているのはここだけらしい\n","                #print(y)\n","                y = self.bbox_util.assign_boxes(y)\n","                #print(y)\n","                inputs.append(img)                \n","                targets.append(y)\n","                if len(targets) == self.batch_size:\n","                    tmp_inp = np.array(inputs)\n","                    tmp_targets = np.array(targets)\n","                    inputs = []\n","                    targets = []\n","                    yield preprocess_input(tmp_inp), tmp_targets\n","\n","path_prefix = './VOCdevkit/VOC2007/JPEGImages/'\n","gen = Generator(gt, bbox_util, 4, path_prefix,\n","                train_keys, val_keys,\n","                (input_shape[0], input_shape[1]), do_crop=False)\n","\n","model = SSD300(input_shape, num_classes=NUM_CLASSES)\n","model.load_weights('params.hdf5', by_name=True)\n","\n","freeze = ['input_1', 'conv1_1', 'conv1_2', 'pool1',\n","          'conv2_1', 'conv2_2', 'pool2',\n","          'conv3_1', 'conv3_2', 'conv3_3', 'pool3']#,\n","#           'conv4_1', 'conv4_2', 'conv4_3', 'pool4']\n","\n","for L in model.layers:\n","    if L.name in freeze:\n","        L.trainable = False\n","\n","def schedule(epoch, decay=0.9):\n","    return base_lr * decay**(epoch)\n","\n","callbacks = [keras.callbacks.ModelCheckpoint('./gdrive/My Drive/data/2007/weights2.{epoch:02d}-{val_loss:.2f}.hdf5',\n","                                             verbose=1,\n","                                             save_weights_only=True),\n","             keras.callbacks.LearningRateScheduler(schedule)]\n","\n","base_lr = 3e-4\n","optim = keras.optimizers.Adam(lr=base_lr)\n","model.compile(optimizer=optim,\n","              loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss)\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/ssd.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_1\", padding=\"same\")`\n","  name='conv1_1')(net['input'])\n","/content/ssd.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_2\", padding=\"same\")`\n","  name='conv1_2')(net['conv1_1'])\n","/content/ssd.py:46: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool1\", padding=\"same\")`\n","  name='pool1')(net['conv1_2'])\n","/content/ssd.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_1\", padding=\"same\")`\n","  name='conv2_1')(net['pool1'])\n","/content/ssd.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_2\", padding=\"same\")`\n","  name='conv2_2')(net['conv2_1'])\n","/content/ssd.py:57: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool2\", padding=\"same\")`\n","  name='pool2')(net['conv2_2'])\n","/content/ssd.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_1\", padding=\"same\")`\n","  name='conv3_1')(net['pool2'])\n","/content/ssd.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_2\", padding=\"same\")`\n","  name='conv3_2')(net['conv3_1'])\n","/content/ssd.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_3\", padding=\"same\")`\n","  name='conv3_3')(net['conv3_2'])\n","/content/ssd.py:72: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool3\", padding=\"same\")`\n","  name='pool3')(net['conv3_3'])\n","/content/ssd.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_1\", padding=\"same\")`\n","  name='conv4_1')(net['pool3'])\n","/content/ssd.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_2\", padding=\"same\")`\n","  name='conv4_2')(net['conv4_1'])\n","/content/ssd.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_3\", padding=\"same\")`\n","  name='conv4_3')(net['conv4_2'])\n","/content/ssd.py:87: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool4\", padding=\"same\")`\n","  name='pool4')(net['conv4_3'])\n","/content/ssd.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_1\", padding=\"same\")`\n","  name='conv5_1')(net['pool4'])\n","/content/ssd.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_2\", padding=\"same\")`\n","  name='conv5_2')(net['conv5_1'])\n","/content/ssd.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_3\", padding=\"same\")`\n","  name='conv5_3')(net['conv5_2'])\n","/content/ssd.py:102: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(1, 1), name=\"pool5\", padding=\"same\")`\n","  name='pool5')(net['conv5_3'])\n","/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:762: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n","  warnings.warn('The `AtrousConvolution2D` layer '\n","/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:766: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\", name=\"fc6\", dilation_rate=(6, 6), padding=\"same\")`\n","  return Conv2D(*args, **kwargs)\n","/content/ssd.py:110: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), activation=\"relu\", name=\"fc7\", padding=\"same\")`\n","  border_mode='same', name='fc7')(net['fc6'])\n","/content/ssd.py:115: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", name=\"conv6_1\", padding=\"same\")`\n","  name='conv6_1')(net['fc7'])\n","/content/ssd.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv6_2\", strides=(2, 2), padding=\"same\")`\n","  name='conv6_2')(net['conv6_1'])\n","/content/ssd.py:122: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv7_1\", padding=\"same\")`\n","  name='conv7_1')(net['conv6_2'])\n","/content/ssd.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv7_2\", strides=(2, 2), padding=\"valid\")`\n","  name='conv7_2')(net['conv7_2'])\n","/content/ssd.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv8_1\", padding=\"same\")`\n","  name='conv8_1')(net['conv7_2'])\n","/content/ssd.py:133: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv8_2\", strides=(2, 2), padding=\"same\")`\n","  name='conv8_2')(net['conv8_1'])\n","/content/ssd.py:140: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv4_3_norm_mbox_loc\", padding=\"same\")`\n","  name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n","/content/ssd.py:148: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(63, (3, 3), name=\"conv4_3_norm_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv4_3_norm'])\n","/content/ssd.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"fc7_mbox_loc\", padding=\"same\")`\n","  name='fc7_mbox_loc')(net['fc7'])\n","/content/ssd.py:168: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"fc7_mbox_conf\", padding=\"same\")`\n","  name=name)(net['fc7'])\n","/content/ssd.py:178: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv6_2_mbox_loc\", padding=\"same\")`\n","  name='conv6_2_mbox_loc')(net['conv6_2'])\n","/content/ssd.py:186: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv6_2_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv6_2'])\n","/content/ssd.py:197: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv7_2_mbox_loc\", padding=\"same\")`\n","  name='conv7_2_mbox_loc')(net['conv7_2'])\n","/content/ssd.py:205: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv7_2_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv7_2'])\n","/content/ssd.py:216: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv8_2_mbox_loc\", padding=\"same\")`\n","  name='conv8_2_mbox_loc')(net['conv8_2'])\n","/content/ssd.py:224: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv8_2_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv8_2'])\n"],"name":"stderr"}]},{"metadata":{"id":"hhgQEv8_1Gp2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"dd542ad5-b1d0-442c-afe0-42d1c28aff63","executionInfo":{"status":"ok","timestamp":1539508065285,"user_tz":-540,"elapsed":795,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["print(gen.generate(False))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["<generator object Generator.generate at 0x7ff377c32db0>\n"],"name":"stdout"}]},{"metadata":{"id":"FJ8Jh2r-Mvni","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":835},"outputId":"b1fda3f7-3428-49d6-f4ab-60089b8fb049","executionInfo":{"status":"ok","timestamp":1539518289515,"user_tz":-540,"elapsed":8744269,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["epochs = 10\n","batch_size = 16\n","history = model.fit_generator(gen.generate(True), \n","                     steps_per_epoch =gen.train_batches//batch_size,\n","                              epochs=epochs, verbose=1,\n","                              callbacks=callbacks,\n","                              validation_data=gen.generate(False),\n","                              validation_steps=gen.val_batches,\n","                              workers=1)\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if issubdtype(ts, int):\n","/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  elif issubdtype(type(size), float):\n"],"name":"stderr"},{"output_type":"stream","text":["856/856 [==============================] - 880s 1s/step - loss: 3.5195 - val_loss: 2.8468\n","\n","Epoch 00001: saving model to ./gdrive/My Drive/data/2007/weights.01-2.85.hdf5\n","Epoch 2/10\n","856/856 [==============================] - 876s 1s/step - loss: 3.3497 - val_loss: 2.5582\n","\n","Epoch 00002: saving model to ./gdrive/My Drive/data/2007/weights.02-2.56.hdf5\n","Epoch 3/10\n","856/856 [==============================] - 875s 1s/step - loss: 3.2599 - val_loss: 2.4713\n","\n","Epoch 00003: saving model to ./gdrive/My Drive/data/2007/weights.03-2.47.hdf5\n","Epoch 4/10\n","856/856 [==============================] - 874s 1s/step - loss: 3.1148 - val_loss: 2.5395\n","\n","Epoch 00004: saving model to ./gdrive/My Drive/data/2007/weights.04-2.54.hdf5\n","Epoch 5/10\n","856/856 [==============================] - 875s 1s/step - loss: 2.9774 - val_loss: 2.4159\n","\n","Epoch 00005: saving model to ./gdrive/My Drive/data/2007/weights.05-2.42.hdf5\n","Epoch 6/10\n","856/856 [==============================] - 874s 1s/step - loss: 2.9521 - val_loss: 2.4816\n","\n","Epoch 00006: saving model to ./gdrive/My Drive/data/2007/weights.06-2.48.hdf5\n","Epoch 7/10\n","856/856 [==============================] - 870s 1s/step - loss: 2.8781 - val_loss: 2.3034\n","\n","Epoch 00007: saving model to ./gdrive/My Drive/data/2007/weights.07-2.30.hdf5\n","Epoch 8/10\n","856/856 [==============================] - 869s 1s/step - loss: 2.8976 - val_loss: 2.3434\n","\n","Epoch 00008: saving model to ./gdrive/My Drive/data/2007/weights.08-2.34.hdf5\n","Epoch 9/10\n","856/856 [==============================] - 870s 1s/step - loss: 2.7091 - val_loss: 2.1960\n","\n","Epoch 00009: saving model to ./gdrive/My Drive/data/2007/weights.09-2.20.hdf5\n","Epoch 10/10\n","856/856 [==============================] - 869s 1s/step - loss: 2.6813 - val_loss: 2.2472\n","\n","Epoch 00010: saving model to ./gdrive/My Drive/data/2007/weights.10-2.25.hdf5\n"],"name":"stdout"}]},{"metadata":{"id":"PLNPAoPoY3Nh","colab_type":"code","colab":{}},"cell_type":"code","source":["open('./gdrive/My Drive/data/2007/model.json', 'w').write(model.to_json())\n","model.save_weights('./gdrive/My Drive/data/2007/param.hdf5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wmFKTVPkQ9WY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"6495fb53-a0e3-4f4e-edbf-777643fbf1b9","executionInfo":{"status":"ok","timestamp":1539506780618,"user_tz":-540,"elapsed":3185,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["%cd ..\n","!ls"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/content\n","2007.zip       prior_boxes_ssd300.pkl  ssd.py\t\tVOC2007.pkl\n","gdrive\t       __pycache__\t       ssd_test.py\tVOCdevkit\n","gt_pascal.pkl  sample_data\t       ssd_training.py\tweights_SSD300.hdf5\n","params.hdf5    ssd_layers.py\t       ssd_utils.py\n"],"name":"stdout"}]},{"metadata":{"id":"ZCVLpZKVMxag","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","inputs = []\n","images = []\n","img_path = path_prefix + sorted(val_keys)[0]\n","img = image.load_img(img_path, target_size=(300, 300))\n","img = image.img_to_array(img)\n","images.append(imread(img_path))\n","inputs.append(img.copy())\n","inputs = preprocess_input(np.array(inputs))\n","\n","preds = model.predict(inputs, batch_size=1, verbose=1)\n","results = bbox_util.detection_out(preds)\n","\n","for i, img in enumerate(images):\n","    # Parse the outputs.\n","    det_label = results[i][:, 0]\n","    det_conf = results[i][:, 1]\n","    det_xmin = results[i][:, 2]\n","    det_ymin = results[i][:, 3]\n","    det_xmax = results[i][:, 4]\n","    det_ymax = results[i][:, 5]\n","\n","    # Get detections with confidence higher than 0.6.\n","    top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.6]\n","\n","    top_conf = det_conf[top_indices]\n","    top_label_indices = det_label[top_indices].tolist()\n","    top_xmin = det_xmin[top_indices]\n","    top_ymin = det_ymin[top_indices]\n","    top_xmax = det_xmax[top_indices]\n","    top_ymax = det_ymax[top_indices]\n","\n","    colors = plt.cm.hsv(np.linspace(0, 1, NUM_CLASSES)).tolist()\n","\n","    plt.imshow(img / 255.)\n","    currentAxis = plt.gca()\n","\n","    for i in range(top_conf.shape[0]):\n","        xmin = int(round(top_xmin[i] * img.shape[1]))\n","        ymin = int(round(top_ymin[i] * img.shape[0]))\n","        xmax = int(round(top_xmax[i] * img.shape[1]))\n","        ymax = int(round(top_ymax[i] * img.shape[0]))\n","        score = top_conf[i]\n","        label = int(top_label_indices[i])\n","        # label_name = voc_classes[label - 1]\n","        display_txt = '{:0.2f}, {}'.format(score, label)\n","        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n","        color = colors[label]\n","        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n","        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n","\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lZHAH2PTNtal","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1348},"outputId":"3fd01ec3-0608-49a1-a8ef-ed44908ec23e","executionInfo":{"status":"ok","timestamp":1539388454760,"user_tz":-540,"elapsed":3889,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["plt.rcParams['figure.figsize'] = (8, 8)\n","plt.rcParams['image.interpolation'] = 'nearest'\n","\n","np.set_printoptions(suppress=True)\n","\n","# 21\n","NUM_CLASSES = 21 #4\n","input_shape = (300, 300, 3)\n","\n","priors = pickle.load(open('prior_boxes_ssd300.pkl', 'rb'))\n","bbox_util = BBoxUtility(NUM_CLASSES, priors)\n","\n","# gt = pickle.load(open('gt_pascal.pkl', 'rb'))\n","gt = pickle.load(open('VOC2007.pkl', 'rb'))\n","keys = sorted(gt.keys())\n","num_train = int(round(0.8 * len(keys)))\n","train_keys = keys[:num_train]\n","val_keys = keys[num_train:]\n","num_val = len(val_keys)\n","\n","class Generator(object):\n","    def __init__(self, gt, bbox_util,\n","                 batch_size, path_prefix,\n","                 train_keys, val_keys, image_size,\n","                 saturation_var=0.5,\n","                 brightness_var=0.5,\n","                 contrast_var=0.5,\n","                 lighting_std=0.5,\n","                 hflip_prob=0.5,\n","                 vflip_prob=0.5,\n","                 do_crop=True,\n","                 crop_area_range=[0.75, 1.0],\n","                 aspect_ratio_range=[3./4., 4./3.]):\n","        self.gt = gt\n","        self.bbox_util = bbox_util\n","        self.batch_size = batch_size\n","        self.path_prefix = path_prefix\n","        self.train_keys = train_keys\n","        self.val_keys = val_keys\n","        self.train_batches = len(train_keys)\n","        self.val_batches = len(val_keys)\n","        self.image_size = image_size\n","        self.color_jitter = []\n","        if saturation_var:\n","            self.saturation_var = saturation_var\n","            self.color_jitter.append(self.saturation)\n","        if brightness_var:\n","            self.brightness_var = brightness_var\n","            self.color_jitter.append(self.brightness)\n","        if contrast_var:\n","            self.contrast_var = contrast_var\n","            self.color_jitter.append(self.contrast)\n","        self.lighting_std = lighting_std\n","        self.hflip_prob = hflip_prob\n","        self.vflip_prob = vflip_prob\n","        self.do_crop = do_crop\n","        self.crop_area_range = crop_area_range\n","        self.aspect_ratio_range = aspect_ratio_range\n","\n","    def grayscale(self, rgb):\n","        return rgb.dot([0.299, 0.587, 0.114])\n","\n","    def saturation(self, rgb):\n","        gs = self.grayscale(rgb)\n","        alpha = 2 * np.random.random() * self.saturation_var\n","        alpha += 1 - self.saturation_var\n","        rgb = rgb * alpha + (1 - alpha) * gs[:, :, None]\n","        return np.clip(rgb, 0, 255)\n","\n","    def brightness(self, rgb):\n","        alpha = 2 * np.random.random() * self.brightness_var\n","        alpha += 1 - self.saturation_var\n","        rgb = rgb * alpha\n","        return np.clip(rgb, 0, 255)\n","\n","    def contrast(self, rgb):\n","        gs = self.grayscale(rgb).mean() * np.ones_like(rgb)\n","        alpha = 2 * np.random.random() * self.contrast_var\n","        alpha += 1 - self.contrast_var\n","        rgb = rgb * alpha + (1 - alpha) * gs\n","        return np.clip(rgb, 0, 255)\n","\n","    def lighting(self, img):\n","        cov = np.cov(img.reshape(-1, 3) / 255.0, rowvar=False)\n","        eigval, eigvec = np.linalg.eigh(cov)\n","        noise = np.random.randn(3) * self.lighting_std\n","        noise = eigvec.dot(eigval * noise) * 255\n","        img += noise\n","        return np.clip(img, 0, 255)\n","\n","    def horizontal_flip(self, img, y):\n","        if np.random.random() < self.hflip_prob:\n","            img = img[:, ::-1]\n","            y[:, [0, 2]] = 1 - y[:, [2, 0]]\n","        return img, y\n","\n","    def vertical_flip(self, img, y):\n","        if np.random.random() < self.vflip_prob:\n","            img = img[::-1]\n","            y[:, [1, 3]] = 1 - y[:, [3, 1]]\n","        return img, y\n","\n","    def random_sized_crop(self, img, targets):\n","        img_w = img.shape[1]\n","        img_h = img.shape[0]\n","        img_area = img_w * img_h\n","        random_scale = np.random.random()\n","        random_scale *= (self.crop_area_range[1] -\n","                         self.crop_area_range[0])\n","        random_scale += self.crop_area_range[0]\n","        target_area = random_scale * img_area\n","        random_ratio = np.random.random()\n","        random_ratio *= (self.aspect_ratio_range[1] -\n","                         self.aspect_ratio_range[0])\n","        random_ratio += self.aspect_ratio_range[0]\n","        w = np.round(np.sqrt(target_area * random_ratio))\n","        h = np.round(np.sqrt(target_area / random_ratio))\n","        if np.random.random() < 0.5:\n","            w, h = h, w\n","        w = min(w, img_w)\n","        w_rel = w / img_w\n","        w = int(w)\n","        h = min(h, img_h)\n","        h_rel = h / img_h\n","        h = int(h)\n","        x = np.random.random() * (img_w - w)\n","        x_rel = x / img_w\n","        x = int(x)\n","        y = np.random.random() * (img_h - h)\n","        y_rel = y / img_h\n","        y = int(y)\n","        img = img[y:y+h, x:x+w]\n","        new_targets = []\n","        for box in targets:\n","            cx = 0.5 * (box[0] + box[2])\n","            cy = 0.5 * (box[1] + box[3])\n","            if (x_rel < cx < x_rel + w_rel and\n","                y_rel < cy < y_rel + h_rel):\n","                xmin = (box[0] - x_rel) / w_rel\n","                ymin = (box[1] - y_rel) / h_rel\n","                xmax = (box[2] - x_rel) / w_rel\n","                ymax = (box[3] - y_rel) / h_rel\n","                xmin = max(0, xmin)\n","                ymin = max(0, ymin)\n","                xmax = min(1, xmax)\n","                ymax = min(1, ymax)\n","                box[:4] = [xmin, ymin, xmax, ymax]\n","                new_targets.append(box)\n","        new_targets = np.asarray(new_targets).reshape(-1, targets.shape[1])\n","        return img, new_targets\n","\n","    def generate(self, train=True):\n","        while True:\n","            if train:\n","                shuffle(self.train_keys)\n","                keys = self.train_keys\n","            else:\n","                shuffle(self.val_keys)\n","                keys = self.val_keys\n","            inputs = []\n","            targets = []\n","            for key in keys:\n","                img_path = self.path_prefix + key\n","                img = imread(img_path).astype('float32')\n","                y = self.gt[key].copy()\n","                if train and self.do_crop:\n","                    img, y = self.random_sized_crop(img, y)\n","                img = imresize(img, self.image_size).astype('float32')\n","                # boxの位置は正規化されているから画像をリサイズしても\n","                # 教師信号としては問題ない\n","                if train:\n","                    shuffle(self.color_jitter)\n","                    for jitter in self.color_jitter:\n","                        img = jitter(img)\n","                    if self.lighting_std:\n","                        img = self.lighting(img)\n","                    if self.hflip_prob > 0:\n","                        img, y = self.horizontal_flip(img, y)\n","                    if self.vflip_prob > 0:\n","                        img, y = self.vertical_flip(img, y)\n","                # 訓練データ生成時にbbox_utilを使っているのはここだけらしい\n","                #print(y)\n","                y = self.bbox_util.assign_boxes(y)\n","                #print(y)\n","                inputs.append(img)\n","                targets.append(y)\n","                if len(targets) == self.batch_size:\n","                    tmp_inp = np.array(inputs)\n","                    tmp_targets = np.array(targets)\n","                    inputs = []\n","                    targets = []\n","                    yield preprocess_input(tmp_inp), tmp_targets\n","\n","path_prefix = './PASCAL_VOC/VOC2012/JPEGImages/'\n","gen = Generator(gt, bbox_util, 1, path_prefix,\n","                train_keys, val_keys,\n","                (input_shape[0], input_shape[1]), do_crop=False)\n","\n","model = SSD300(input_shape, num_classes=NUM_CLASSES)\n","model.load_weights('weights_SSD300.hdf5', by_name=True)\n","\n","freeze = ['input_1', 'conv1_1', 'conv1_2', 'pool1',\n","          'conv2_1', 'conv2_2', 'pool2',\n","          'conv3_1', 'conv3_2', 'conv3_3', 'pool3']#,\n","#           'conv4_1', 'conv4_2', 'conv4_3', 'pool4']\n","\n","for L in model.layers:\n","    if L.name in freeze:\n","        L.trainable = False\n","\n","def schedule(epoch, decay=0.9):\n","    return base_lr * decay**(epoch)\n","\n","callbacks = [keras.callbacks.ModelCheckpoint('./checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n","                                             verbose=1,\n","                                             save_weights_only=True),\n","             keras.callbacks.LearningRateScheduler(schedule)]\n","\n","base_lr = 3e-4\n","optim = keras.optimizers.Adam(lr=base_lr)\n","model.compile(optimizer=optim,\n","              loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss)\n","\n","nb_epoch = 20\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/ssd.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_1\", padding=\"same\")`\n","  name='conv1_1')(net['input'])\n","/content/ssd.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_2\", padding=\"same\")`\n","  name='conv1_2')(net['conv1_1'])\n","/content/ssd.py:46: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool1\", padding=\"same\")`\n","  name='pool1')(net['conv1_2'])\n","/content/ssd.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_1\", padding=\"same\")`\n","  name='conv2_1')(net['pool1'])\n","/content/ssd.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_2\", padding=\"same\")`\n","  name='conv2_2')(net['conv2_1'])\n","/content/ssd.py:57: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool2\", padding=\"same\")`\n","  name='pool2')(net['conv2_2'])\n","/content/ssd.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_1\", padding=\"same\")`\n","  name='conv3_1')(net['pool2'])\n","/content/ssd.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_2\", padding=\"same\")`\n","  name='conv3_2')(net['conv3_1'])\n","/content/ssd.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_3\", padding=\"same\")`\n","  name='conv3_3')(net['conv3_2'])\n","/content/ssd.py:72: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool3\", padding=\"same\")`\n","  name='pool3')(net['conv3_3'])\n","/content/ssd.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_1\", padding=\"same\")`\n","  name='conv4_1')(net['pool3'])\n","/content/ssd.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_2\", padding=\"same\")`\n","  name='conv4_2')(net['conv4_1'])\n","/content/ssd.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_3\", padding=\"same\")`\n","  name='conv4_3')(net['conv4_2'])\n","/content/ssd.py:87: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool4\", padding=\"same\")`\n","  name='pool4')(net['conv4_3'])\n","/content/ssd.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_1\", padding=\"same\")`\n","  name='conv5_1')(net['pool4'])\n","/content/ssd.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_2\", padding=\"same\")`\n","  name='conv5_2')(net['conv5_1'])\n","/content/ssd.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_3\", padding=\"same\")`\n","  name='conv5_3')(net['conv5_2'])\n","/content/ssd.py:102: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(1, 1), name=\"pool5\", padding=\"same\")`\n","  name='pool5')(net['conv5_3'])\n","/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:762: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n","  warnings.warn('The `AtrousConvolution2D` layer '\n","/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:766: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\", name=\"fc6\", dilation_rate=(6, 6), padding=\"same\")`\n","  return Conv2D(*args, **kwargs)\n","/content/ssd.py:110: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), activation=\"relu\", name=\"fc7\", padding=\"same\")`\n","  border_mode='same', name='fc7')(net['fc6'])\n","/content/ssd.py:115: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", name=\"conv6_1\", padding=\"same\")`\n","  name='conv6_1')(net['fc7'])\n","/content/ssd.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv6_2\", strides=(2, 2), padding=\"same\")`\n","  name='conv6_2')(net['conv6_1'])\n","/content/ssd.py:122: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv7_1\", padding=\"same\")`\n","  name='conv7_1')(net['conv6_2'])\n","/content/ssd.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv7_2\", strides=(2, 2), padding=\"valid\")`\n","  name='conv7_2')(net['conv7_2'])\n","/content/ssd.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv8_1\", padding=\"same\")`\n","  name='conv8_1')(net['conv7_2'])\n","/content/ssd.py:133: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv8_2\", strides=(2, 2), padding=\"same\")`\n","  name='conv8_2')(net['conv8_1'])\n","/content/ssd.py:140: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv4_3_norm_mbox_loc\", padding=\"same\")`\n","  name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n","/content/ssd.py:148: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(63, (3, 3), name=\"conv4_3_norm_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv4_3_norm'])\n","/content/ssd.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"fc7_mbox_loc\", padding=\"same\")`\n","  name='fc7_mbox_loc')(net['fc7'])\n","/content/ssd.py:168: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"fc7_mbox_conf\", padding=\"same\")`\n","  name=name)(net['fc7'])\n","/content/ssd.py:178: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv6_2_mbox_loc\", padding=\"same\")`\n","  name='conv6_2_mbox_loc')(net['conv6_2'])\n","/content/ssd.py:186: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv6_2_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv6_2'])\n","/content/ssd.py:197: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv7_2_mbox_loc\", padding=\"same\")`\n","  name='conv7_2_mbox_loc')(net['conv7_2'])\n","/content/ssd.py:205: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv7_2_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv7_2'])\n","/content/ssd.py:216: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv8_2_mbox_loc\", padding=\"same\")`\n","  name='conv8_2_mbox_loc')(net['conv8_2'])\n","/content/ssd.py:224: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv8_2_mbox_conf\", padding=\"same\")`\n","  name=name)(net['conv8_2'])\n"],"name":"stderr"}]},{"metadata":{"id":"CZ_O3MiJplbX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1446},"outputId":"dfaa0b59-7a4e-4f52-957d-88a5cba27467","executionInfo":{"status":"error","timestamp":1539393327161,"user_tz":-540,"elapsed":4872390,"user":{"displayName":"武藤熙麟","photoUrl":"","userId":"16762842130569802091"}}},"cell_type":"code","source":["history = model.fit_generator(gen.generate(True), gen.train_batches,\n","                              epochs=nb_epoch, verbose=1,\n","                              callbacks=callbacks,\n","                              validation_data=gen.generate(False),\n","                              nb_val_samples=gen.val_batches,\n","                              nb_worker=1)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 13700, 20, verbose=1, callbacks=[<keras.ca..., validation_data=<generator..., validation_steps=3425, workers=1)`\n","  \n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if issubdtype(ts, int):\n","/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  elif issubdtype(type(size), float):\n"],"name":"stderr"},{"output_type":"stream","text":["13700/13700 [==============================] - 4868s 355ms/step - loss: 3.2423 - val_loss: 2.7440\n","\n","Epoch 00001: saving model to ./checkpoints/weights.01-2.74.hdf5\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-340e56503dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               nb_worker=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2266\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m                 \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    454\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   2619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2621\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2622\u001b[0m             \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = './checkpoints/weights.01-2.74.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"]}]},{"metadata":{"id":"pHgzS8amsPrd","colab_type":"code","colab":{}},"cell_type":"code","source":["open('./gdrive/My Drive/data/2007/model.json', 'w').write(model.to_json())\n","model.save_weights('./gdrive/My Drive/data/2007/param.hdf5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xn-0ko-vpmW3","colab_type":"code","colab":{}},"cell_type":"code","source":["history = model.fit_generator(gen.generate(True), gen.train_batches,\n","                              nb_epoch, verbose=1,\n","                              callbacks=callbacks,\n","                              validation_data=gen.generate(False),\n","                              nb_val_samples=gen.val_batches,\n","                              nb_worker=1)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bMPkufwLpm88","colab_type":"code","colab":{}},"cell_type":"code","source":["history = model.fit_generator(gen.generate(True), gen.train_batches,\n","                              nb_epoch, verbose=1,\n","                              callbacks=callbacks,\n","                              validation_data=gen.generate(False),\n","                              nb_val_samples=gen.val_batches,\n","                              nb_worker=1)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I_8YvByzpo9D","colab_type":"code","colab":{}},"cell_type":"code","source":["history = model.fit_generator(gen.generate(True), gen.train_batches,\n","                              nb_epoch, verbose=1,\n","                              callbacks=callbacks,\n","                              validation_data=gen.generate(False),\n","                              nb_val_samples=gen.val_batches,\n","                              nb_worker=1)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"byUew0l9S0Wo","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","inputs = []\n","images = []\n","img_path = path_prefix + sorted(val_keys)[0]\n","img = image.load_img(img_path, target_size=(300, 300))\n","img = image.img_to_array(img)\n","images.append(imread(img_path))\n","inputs.append(img.copy())\n","inputs = preprocess_input(np.array(inputs))\n","\n","preds = model.predict(inputs, batch_size=1, verbose=1)\n","results = bbox_util.detection_out(preds)\n","\n","for i, img in enumerate(images):\n","    # Parse the outputs.\n","    det_label = results[i][:, 0]\n","    det_conf = results[i][:, 1]\n","    det_xmin = results[i][:, 2]\n","    det_ymin = results[i][:, 3]\n","    det_xmax = results[i][:, 4]\n","    det_ymax = results[i][:, 5]\n","\n","    # Get detections with confidence higher than 0.6.\n","    top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.6]\n","\n","    top_conf = det_conf[top_indices]\n","    top_label_indices = det_label[top_indices].tolist()\n","    top_xmin = det_xmin[top_indices]\n","    top_ymin = det_ymin[top_indices]\n","    top_xmax = det_xmax[top_indices]\n","    top_ymax = det_ymax[top_indices]\n","\n","    colors = plt.cm.hsv(np.linspace(0, 1, NUM_CLASSES)).tolist()\n","\n","    plt.imshow(img / 255.)\n","    currentAxis = plt.gca()\n","\n","    for i in range(top_conf.shape[0]):\n","        xmin = int(round(top_xmin[i] * img.shape[1]))\n","        ymin = int(round(top_ymin[i] * img.shape[0]))\n","        xmax = int(round(top_xmax[i] * img.shape[1]))\n","        ymax = int(round(top_ymax[i] * img.shape[0]))\n","        score = top_conf[i]\n","        label = int(top_label_indices[i])\n","        # label_name = voc_classes[label - 1]\n","        display_txt = '{:0.2f}, {}'.format(score, label)\n","        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n","        color = colors[label]\n","        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n","        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n","\n","    plt.show()\n"],"execution_count":0,"outputs":[]}]}